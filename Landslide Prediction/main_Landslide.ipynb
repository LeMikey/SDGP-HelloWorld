{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "main_Landslide.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNqcne91U8ouZkLcn9xFXPe",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LeMikey/SDGP-HelloWorld/blob/main/main_Landslide.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Landslide Prediction System**"
      ],
      "metadata": {
        "id": "m3d-KCO5nCyx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Imports and installation**"
      ],
      "metadata": {
        "id": "cQstfmDinWaZ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W0gASO_dOlTD"
      },
      "outputs": [],
      "source": [
        "!pip install pytorch_tabnet "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from pytorch_tabnet.tab_model import TabNetClassifier\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "from sklearn.metrics import roc_auc_score\n",
        "np.random.seed(0)\n",
        "from matplotlib import pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import QuantileTransformer,  KBinsDiscretizer\n",
        "from sklearn.impute import SimpleImputer\n",
        "\n",
        "import torch\n",
        "\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "from sklearn.model_selection import KFold\n",
        "import torch\n",
        "\n",
        "%matplotlib inline"
      ],
      "metadata": {
        "id": "14DWxQj6QUxJ"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Dataset collection and altering**"
      ],
      "metadata": {
        "id": "k_TMHi74nh4S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "trainSet = pd.read_csv('train-landslide-dataset.csv')\n",
        "testSet = pd.read_csv('test-landslide-dataset.csv')\n",
        "\n",
        "trainSet['Landslide'] = trainSet['Landslide'].astype(str)\n",
        "\n",
        "features = [col for col in trainSet.columns if col not in ['Landslide']]\n",
        "\n",
        "pipe = Pipeline([\n",
        "        ('imputer', SimpleImputer(strategy='median',missing_values=np.nan)),\n",
        "        (\"scaler\", QuantileTransformer(n_quantiles=200, output_distribution='normal'))\n",
        "        ])\n",
        "X = pipe.fit_transform(trainSet[features])\n",
        "X_test=pipe.transform(testSet[features])"
      ],
      "metadata": {
        "id": "d3snP6ZwjD94"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainSet.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ljw09NcDsieq",
        "outputId": "3d55b7ea-48ff-4cd1-cd1a-86d4a301303f"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1212, 13)"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Machine Learning Model"
      ],
      "metadata": {
        "id": "Ad5Xld2tnyr6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tabnet_params = dict(n_steps = 1,\n",
        "                   optimizer_fn=torch.optim.Adam,\n",
        "                   optimizer_params=dict(lr=1e-2, weight_decay = 5e-4),\n",
        "                   scheduler_params={\"step_size\":1,\n",
        "                                     \"gamma\":0.9},\n",
        "                   scheduler_fn=torch.optim.lr_scheduler.StepLR,\n",
        "                   mask_type='entmax',\n",
        "                   verbose = 5)\n",
        "\n",
        "kf = KFold(n_splits=5, random_state = 40, shuffle = True)\n",
        "preds = np.zeros((243,))\n",
        "for  fold , (train_index, test_index) in enumerate(kf.split(X)):\n",
        "    print(20*\"*\")\n",
        "    print(\"Fold {}:\".format(fold))\n",
        "    X_train, X_valid = X[train_index], X[test_index]\n",
        "    y_train, y_valid = trainSet.Landslide[train_index].values, trainSet.Landslide[test_index].values\n",
        "\n",
        "    clf = TabNetClassifier(**tabnet_params)\n",
        "    clf.fit(\n",
        "        X_train=X_train, y_train=y_train,\n",
        "        eval_set=[(X_train, y_train), (X_valid, y_valid)],\n",
        "        eval_name=['train', 'valid'],\n",
        "        eval_metric=['auc'],\n",
        "        max_epochs= 100, patience=5,\n",
        "        batch_size=1024*10, virtual_batch_size=128*10,\n",
        "        num_workers=0,\n",
        "        weights=1,\n",
        "        drop_last=False)\n",
        "     \n",
        "    preds += clf.predict_proba(X_test)[:, 1]\n",
        "    print(preds.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "VfRJrkLgn_A5",
        "outputId": "4f350750-e503-4b8d-8f0b-be40cf8735c0"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "********************\n",
            "Fold 0:\n",
            "Device used : cpu\n",
            "epoch 0  | loss: 0.69087 | train_auc: 0.53123 | valid_auc: 0.50173 |  0:00:00s\n",
            "epoch 5  | loss: 0.62337 | train_auc: 0.57789 | valid_auc: 0.55935 |  0:00:00s\n",
            "\n",
            "Early stopping occurred at epoch 9 with best_epoch = 4 and best_valid_auc = 0.57655\n",
            "Best weights from best epoch are automatically used!\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-070507ecd655>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     28\u001b[0m         drop_last=False)\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m     \u001b[0mpreds\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: operands could not be broadcast together with shapes (243,) (1212,) (243,) "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "submissionData = pd.read_csv('submission-file.csv')\n",
        "submissionData"
      ],
      "metadata": {
        "id": "tm9262aqq0ly"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}