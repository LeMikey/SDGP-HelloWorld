{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "main_Landslide.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMOrrDSWQZIcGmsS9zELp24",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LeMikey/SDGP-HelloWorld/blob/main/main_Landslide.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Landslide Prediction System**"
      ],
      "metadata": {
        "id": "m3d-KCO5nCyx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Imports and installation**"
      ],
      "metadata": {
        "id": "cQstfmDinWaZ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W0gASO_dOlTD"
      },
      "outputs": [],
      "source": [
        "!pip install pytorch_tabnet "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from pytorch_tabnet.tab_model import TabNetClassifier\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "from sklearn.metrics import roc_auc_score\n",
        "np.random.seed(0)\n",
        "from matplotlib import pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import QuantileTransformer,  KBinsDiscretizer\n",
        "from sklearn.impute import SimpleImputer\n",
        "\n",
        "import torch\n",
        "\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "from sklearn.model_selection import KFold\n",
        "import torch\n",
        "from sklearn.metrics import accuracy_score,confusion_matrix\n",
        "\n",
        "%matplotlib inline"
      ],
      "metadata": {
        "id": "14DWxQj6QUxJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Dataset collection and altering**"
      ],
      "metadata": {
        "id": "k_TMHi74nh4S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "trainSet = pd.read_csv('train-landslide-dataset.csv')\n",
        "testSet = pd.read_csv('test-landslide-dataset.csv')\n",
        "\n",
        "trainSet['Landslide'] = trainSet['Landslide'].astype(str)\n",
        "\n",
        "features = [col for col in trainSet.columns if col not in ['Landslide']]\n",
        "\n",
        "pipe = Pipeline([\n",
        "        ('imputer', SimpleImputer(strategy='median',missing_values=np.nan)),\n",
        "        (\"scaler\", QuantileTransformer(n_quantiles=200, output_distribution='normal'))\n",
        "        ])\n",
        "X = pipe.fit_transform(trainSet[features])\n",
        "X_test=pipe.transform(testSet[features])"
      ],
      "metadata": {
        "id": "d3snP6ZwjD94"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainSet.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ljw09NcDsieq",
        "outputId": "3bdf36ff-3fbb-4101-86b7-ba7beff88e0b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1212, 13)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Machine Learning Model"
      ],
      "metadata": {
        "id": "Ad5Xld2tnyr6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tabnet_params = dict(n_steps = 1,\n",
        "                   optimizer_fn=torch.optim.Adam,\n",
        "                   optimizer_params=dict(lr=1e-2, weight_decay = 5e-4),\n",
        "                   scheduler_params={\"step_size\":1,\n",
        "                                     \"gamma\":0.9},\n",
        "                   scheduler_fn=torch.optim.lr_scheduler.StepLR,\n",
        "                   mask_type='entmax',\n",
        "\n",
        "                   verbose = 5)"
      ],
      "metadata": {
        "id": "3OUpKmh9HocT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "kf = KFold(n_splits=5, random_state = 40, shuffle = True)\n",
        "preds = np.zeros((243,))\n",
        "for  fold , (train_index, test_index) in enumerate(kf.split(X)):\n",
        "    print(20*\"*\")\n",
        "    print(\"Fold {}:\".format(fold))\n",
        "    X_train, X_valid = X[train_index], X[test_index]\n",
        "    y_train, y_valid = trainSet.Landslide[train_index].values, trainSet.Landslide[test_index].values\n",
        "\n",
        "    clf = TabNetClassifier(**tabnet_params)\n",
        "    clf.fit(\n",
        "        X_train=X_train, y_train=y_train,\n",
        "        eval_set=[(X_train, y_train), (X_valid, y_valid)],\n",
        "        eval_name=['train', 'valid'],\n",
        "        eval_metric=['auc'],\n",
        "        max_epochs= 100, patience=5,\n",
        "        batch_size=1024*10, virtual_batch_size=128*10,\n",
        "        num_workers=0,\n",
        "        weights=1,\n",
        "        drop_last=False)\n",
        "     \n",
        "    print(preds.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "VfRJrkLgn_A5",
        "outputId": "544d94b9-2aeb-4550-e446-a45f41d3c047"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "********************\n",
            "Fold 0:\n",
            "Device used : cpu\n",
            "epoch 0  | loss: 0.69087 | train_auc: 0.53123 | valid_auc: 0.50173 |  0:00:00s\n",
            "epoch 5  | loss: 0.62337 | train_auc: 0.57789 | valid_auc: 0.55935 |  0:00:00s\n",
            "\n",
            "Early stopping occurred at epoch 9 with best_epoch = 4 and best_valid_auc = 0.57655\n",
            "Best weights from best epoch are automatically used!\n",
            "(243,)\n",
            "********************\n",
            "Fold 1:\n",
            "Device used : cpu\n",
            "epoch 0  | loss: 0.69004 | train_auc: 0.53805 | valid_auc: 0.50425 |  0:00:00s\n",
            "epoch 5  | loss: 0.6196  | train_auc: 0.5622  | valid_auc: 0.50408 |  0:00:00s\n",
            "epoch 10 | loss: 0.61708 | train_auc: 0.58293 | valid_auc: 0.53288 |  0:00:00s\n",
            "epoch 15 | loss: 0.58324 | train_auc: 0.62897 | valid_auc: 0.55747 |  0:00:00s\n",
            "epoch 20 | loss: 0.58229 | train_auc: 0.65136 | valid_auc: 0.57931 |  0:00:01s\n",
            "epoch 25 | loss: 0.57636 | train_auc: 0.6596  | valid_auc: 0.59905 |  0:00:01s\n",
            "epoch 30 | loss: 0.57279 | train_auc: 0.67285 | valid_auc: 0.61457 |  0:00:01s\n",
            "epoch 35 | loss: 0.57447 | train_auc: 0.69114 | valid_auc: 0.63757 |  0:00:01s\n",
            "epoch 40 | loss: 0.55766 | train_auc: 0.70151 | valid_auc: 0.66539 |  0:00:01s\n",
            "epoch 45 | loss: 0.56643 | train_auc: 0.71008 | valid_auc: 0.67711 |  0:00:02s\n",
            "epoch 50 | loss: 0.56551 | train_auc: 0.71431 | valid_auc: 0.68597 |  0:00:02s\n",
            "epoch 55 | loss: 0.56422 | train_auc: 0.71726 | valid_auc: 0.68849 |  0:00:02s\n",
            "\n",
            "Early stopping occurred at epoch 57 with best_epoch = 52 and best_valid_auc = 0.68849\n",
            "Best weights from best epoch are automatically used!\n",
            "(243,)\n",
            "********************\n",
            "Fold 2:\n",
            "Device used : cpu\n",
            "epoch 0  | loss: 0.6829  | train_auc: 0.52503 | valid_auc: 0.52875 |  0:00:00s\n",
            "epoch 5  | loss: 0.63694 | train_auc: 0.57013 | valid_auc: 0.55822 |  0:00:00s\n",
            "\n",
            "Early stopping occurred at epoch 7 with best_epoch = 2 and best_valid_auc = 0.57969\n",
            "Best weights from best epoch are automatically used!\n",
            "(243,)\n",
            "********************\n",
            "Fold 3:\n",
            "Device used : cpu\n",
            "epoch 0  | loss: 0.6795  | train_auc: 0.51022 | valid_auc: 0.5832  |  0:00:00s\n",
            "epoch 5  | loss: 0.62989 | train_auc: 0.5484  | valid_auc: 0.59129 |  0:00:00s\n",
            "\n",
            "Early stopping occurred at epoch 9 with best_epoch = 4 and best_valid_auc = 0.60813\n",
            "Best weights from best epoch are automatically used!\n",
            "(243,)\n",
            "********************\n",
            "Fold 4:\n",
            "Device used : cpu\n",
            "epoch 0  | loss: 0.68932 | train_auc: 0.52481 | valid_auc: 0.50855 |  0:00:00s\n",
            "epoch 5  | loss: 0.6245  | train_auc: 0.54328 | valid_auc: 0.52295 |  0:00:00s\n",
            "\n",
            "Early stopping occurred at epoch 7 with best_epoch = 2 and best_valid_auc = 0.56619\n",
            "Best weights from best epoch are automatically used!\n",
            "(243,)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-29-34f481c757df>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Accuracy:%.2f'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mX_valid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_valid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpreds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36maccuracy_score\u001b[0;34m(y_true, y_pred, normalize, sample_weight)\u001b[0m\n\u001b[1;32m    209\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m     \u001b[0;31m# Compute accuracy for each possible representation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m     \u001b[0my_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0my_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"multilabel\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36m_check_targets\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m     82\u001b[0m     \u001b[0my_pred\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0marray\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mindicator\u001b[0m \u001b[0mmatrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m     \"\"\"\n\u001b[0;32m---> 84\u001b[0;31m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     85\u001b[0m     \u001b[0mtype_true\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m     \u001b[0mtype_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    332\u001b[0m         raise ValueError(\n\u001b[1;32m    333\u001b[0m             \u001b[0;34m\"Found input variables with inconsistent numbers of samples: %r\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 334\u001b[0;31m             \u001b[0;34m%\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlengths\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    335\u001b[0m         )\n\u001b[1;32m    336\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [2, 243]"
          ]
        }
      ]
    }
  ]
}